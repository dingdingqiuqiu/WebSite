# 温和地走进深度学习

偶然看到的一个关于深度学习的综述，让我受益匪浅。  
同时也感受到了什么叫一个高质量综述和高质量组会  
[温和地走进深度学习_bilibili](https://www.bilibili.com/video/BV1Sr421u7eF/?spm_id_from=333.337.search-card.all.click&vd_source=4e1dceccc918063def66c9d643674c6a
)

![image-20250316104308662](./assets/image-20250316104308662.png)

![image-20250315190539833](./assets/image-20250315190539833.png)

![image-20250315214929901](./assets/image-20250315214929901.png)

![image-20250315220527369](./assets/image-20250315220527369.png)

![image-20250315220558254](./assets/image-20250315220558254.png)

![image-20250315220640858](./assets/image-20250315220640858.png)

![image-20250315220742492](./assets/image-20250315220742492.png)

在原本的卷积外面补一圈数（0或其他），再卷积，实现升维

$3*3$ ->$7*7$ ->$5*5$

![image-20250315221012689](./assets/image-20250315221012689.png)

![image-20250315221102952](./assets/image-20250315221102952.png)

![image-20250315221116833](./assets/image-20250315221116833.png)

每一层隐藏层之间也有连接，出来一个结果之后，再输入一个新的

![image-20250315221205745](./assets/image-20250315221205745.png)

RNN每一步只记住前一步的东西，记忆很短暂，LSTM可以记住之前的信息，多加入一个C

![image-20250315221800285](./assets/image-20250315221800285.png)

词嵌入：将一个词转化成一个向量（下面两者的折中，既考虑维度又考虑距离）

分词器：一个数表达一个词 （一个词可能有多种含义，没有维度，但是数字可以表示距离）

one-hot：什么类别写1[0,0,01.....]（无法表达相似性，可以表达维度（什么类别）但是无法表达距离）

![image-20250315221815254](./assets/image-20250315221815254.png)

![image-20250315222336201](./assets/image-20250315222336201.png)

更像卷积，输入X

![image-20250315222349242](./assets/image-20250315222349242.png)

![image-20250315222403866](./assets/image-20250315222403866.png)

![image-20250315222513281](./assets/image-20250315222513281.png)

![image-20250315222612913](./assets/image-20250315222612913.png)

![image-20250315222808639](./assets/image-20250315222808639.png)

听不懂

![image-20250315223314495](./assets/image-20250315223314495.png)

attention关注整个句子，CNN关注一个感受野，在数据多的情况效果更好，但是更难训练

![image-20250315223523202](./assets/image-20250315223523202.png)

Attention并行 lstm是并行

![image-20250315223613968](./assets/image-20250315223613968.png)

![image-20250315223715337](./assets/image-20250315223715337.png)

类似于RNN，每一步考虑前一步

![image-20250315223839387](./assets/image-20250315223839387.png)

![image-20250316105130728](./assets/image-20250316105130728.png)

![image-20250316105145373](./assets/image-20250316105145373.png)

![image-20250316105200985](./assets/image-20250316105200985.png)

![image-20250316105544864](./assets/image-20250316105544864.png)

![image-20250316105637117](./assets/image-20250316105637117.png)

![image-20250316105754549](./assets/image-20250316105754549.png)

![image-20250316110541018](./assets/image-20250316110541018.png)

类似于先压缩后解压的感觉，举例如下

![image-20250316110735668](./assets/image-20250316110735668.png)

![image-20250316110802558](./assets/image-20250316110802558.png)

CNN、RNN缺陷：视野空间有限，无法把握全局信息

![image-20250316111244330](./assets/image-20250316111244330.png)

我希望$x_1$和$x_4$可以快速的联系到一起，编码之后的向量还能和之前同一个维度

![image-20250316111356211](./assets/image-20250316111356211.png)

![image-20250316111544152](./assets/image-20250316111544152.png)

![image-20250316111852827](./assets/image-20250316111852827.png)

但是没有参数变量，只是将各个数据复制下来，相当于算子，且可以预测注意力分数，$a_1$$a_1$之间肯定注意力分数最大，因为相似度最高。计算相似度也是有很多算法的，一般使用余弦值，内积

![image-20250316112141286](./assets/image-20250316112141286.png)

加入MLP，使之可以学习

![image-20250316112213056](./assets/image-20250316112213056.png)

![image-20250316112240407](./assets/image-20250316112240407.png)

 ![image-20250316112550586](./assets/image-20250316112550586.png)

![image-20250316113333724](./assets/image-20250316113333724.png)

![1](./assets/image-20250316113639902.png)

![image-20250316113656923](./assets/image-20250316113656923.png)

![image-20250316114159140](./assets/image-20250316114159140.png)

预训练，在一些很通用的模型上进行训练，之后再在下游模型上训练

GPT用Transformer 的Decoder

![image-20250316114614641](./assets/image-20250316114614641.png)

![image-20250316114802792](./assets/image-20250316114802792.png)

![image-20250316114820185](./assets/image-20250316114820185.png)

BERT用Transformer 的Encoder

![image-20250316114911258](./assets/image-20250316114911258.png)

![image-20250316114953516](./assets/image-20250316114953516.png)

![image-20250316115256426](./assets/image-20250316115256426.png)

![image-20250316115315795](./assets/image-20250316115315795.png)

![image-20250316115445801](./assets/image-20250316115445801.png)

![image-20250316115851751](./assets/image-20250316115851751.png)
